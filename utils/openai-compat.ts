import { Message as VercelChatMessage } from 'ai';

// OpenAI API è¯·æ±‚æ ¼å¼
export interface OpenAICompletionRequest {
  model: string;
  messages: OpenAIMessage[];
  temperature?: number;
  max_tokens?: number;
  top_p?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  stop?: string | string[];
  stream?: boolean;
  tools?: OpenAITool[];
  tool_choice?: string | object;
  user?: string;
}

export interface OpenAIMessage {
  role: 'system' | 'user' | 'assistant' | 'tool';
  content: string | OpenAIMessageContent[];
  name?: string;
  tool_calls?: OpenAIToolCall[];
  tool_call_id?: string;
}

export interface OpenAIMessageContent {
  type: 'text' | 'image_url';
  text?: string;
  image_url?: {
    url: string;
    detail?: 'low' | 'high' | 'auto';
  };
}

export interface OpenAITool {
  type: 'function';
  function: {
    name: string;
    description?: string;
    parameters?: object;
  };
}

export interface OpenAIToolCall {
  id: string;
  type: 'function';
  function: {
    name: string;
    arguments: string;
  };
}

// OpenAI API å“åº”æ ¼å¼
export interface OpenAICompletionResponse {
  id: string;
  object: 'chat.completion' | 'chat.completion.chunk';
  created: number;
  model: string;
  choices: OpenAIChoice[];
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export interface OpenAIChoice {
  index: number;
  message?: OpenAIMessage;
  delta?: Partial<OpenAIMessage>;
  finish_reason?: 'stop' | 'length' | 'tool_calls' | 'content_filter' | null;
}

// æ¨¡å‹æ˜ å°„é…ç½®
export const MODEL_MAPPING: Record<string, string> = {
  // OpenAI æ¨¡å‹æ˜ å°„
  'gpt-4': 'gpt-4o-all',
  'gpt-4-turbo': 'gpt-4o-all',
  'gpt-4o': 'gpt-4o-all',
  'gpt-4o-mini': 'o4-mini',
  'gpt-3.5-turbo': 'gemini-flash-lite',
  
  // Claude æ¨¡å‹æ˜ å°„
  'claude-3-5-sonnet': 'claude-sonnet-4-all',
  'claude-3-sonnet': 'claude-sonnet-4-all',
  'claude-3-haiku': 'gemini-flash-lite',
  
  // Gemini æ¨¡å‹æ˜ å°„
  'gemini-pro': 'gemini-flash',
  'gemini-1.5-pro': 'gemini-flash',
  'gemini-1.5-flash': 'gemini-flash-lite',
  
  // è‡ªå®šä¹‰æ¨¡å‹
  'auto': 'auto', // ç‰¹æ®Šæ ‡è¯†ï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹
  'langchain-chat': 'auto',
  'langchain-vision': 'gpt-4o-all',
  'langchain-search': 'gemini-flash',
  'langchain-reasoning': 'deepseek-reasoner',
  'langchain-structured': 'gpt-4o-all',
  
  // DeepSeek æ¨¡å‹æ˜ å°„
  'deepseek-chat': 'deepseek-chat',
  'deepseek-coder': 'deepseek-chat',
  
  // é€šä¹‰åƒé—®æ¨¡å‹æ˜ å°„
  'qwen-turbo': 'qwen-turbo',
  'qwen-plus': 'qwen-turbo',
  'qwen-max': 'qwen-turbo',
  
  // è…¾è®¯æ··å…ƒæ¨¡å‹æ˜ å°„
  'hunyuan-turbo': 'hunyuan-turbos-latest',
  'hunyuan-turbos': 'hunyuan-turbos-latest',
  'hunyuan-turbos-latest': 'hunyuan-turbos-latest',
  'hunyuan-t1': 'hunyuan-t1-latest',
  'hunyuan-t1-latest': 'hunyuan-t1-latest',
};

// Autoæ¨¡å‹æ™ºèƒ½é€‰æ‹©é€»è¾‘
export function selectBestModelForAuto(request: OpenAICompletionRequest): string {
  const lastMessage = request.messages[request.messages.length - 1];
  const content = Array.isArray(lastMessage.content) 
    ? lastMessage.content.map(c => c.type === 'text' ? c.text : '').join(' ')
    : lastMessage.content;

  // æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡ - è§†è§‰èƒ½åŠ›
  const hasImage = request.messages.some(msg => 
    Array.isArray(msg.content) && 
    msg.content.some(c => c.type === 'image_url')
  );

  if (hasImage) {
    return 'gpt-4o-all'; // æœ€ä½³è§†è§‰æ¨¡å‹
  }

  const lowerContent = content.toLowerCase();

  // æ£€æµ‹è”ç½‘æœç´¢éœ€æ±‚
  if (lowerContent.includes('search') || 
      lowerContent.includes('latest') || 
      lowerContent.includes('current') ||
      lowerContent.includes('news') ||
      lowerContent.includes('today') ||
      lowerContent.includes('recent')) {
    return 'gemini-flash'; // æ”¯æŒæœç´¢çš„æ¨¡å‹
  }

  // æ£€æµ‹å·¥å…·è°ƒç”¨éœ€æ±‚
  if (request.tools && request.tools.length > 0 ||
      lowerContent.includes('tool') || 
      lowerContent.includes('function') || 
      lowerContent.includes('calculate') ||
      lowerContent.includes('compute')) {
    return 'gpt-4o-all'; // æœ€ä½³å·¥å…·è°ƒç”¨æ¨¡å‹
  }

  // æ£€æµ‹å¤æ‚æ¨ç†éœ€æ±‚
  if (lowerContent.includes('analyze') || 
      lowerContent.includes('reasoning') || 
      lowerContent.includes('logic') ||
      lowerContent.includes('solve') ||
      lowerContent.includes('explain') ||
      lowerContent.includes('why') ||
      lowerContent.includes('how') ||
      content.length > 500) { // é•¿æ–‡æœ¬é€šå¸¸éœ€è¦æ¨ç†
    return 'deepseek-reasoner'; // æœ€ä½³æ¨ç†æ¨¡å‹
  }

  // æ£€æµ‹ç»“æ„åŒ–è¾“å‡ºéœ€æ±‚
  if (lowerContent.includes('json') || 
      lowerContent.includes('format') || 
      lowerContent.includes('structure') ||
      lowerContent.includes('table') ||
      lowerContent.includes('list')) {
    return 'gpt-4o-all'; // æœ€ä½³ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
  }

  // æ£€æµ‹ä¸­æ–‡å†…å®¹
  const chineseChars = (content.match(/[\u4E00-\u9FFF]/g) || []).length;
  const totalChars = content.length;
  const isChineseContent = totalChars > 0 && (chineseChars / totalChars) > 0.3;

  if (isChineseContent) {
    // æ ¹æ®å¤æ‚åº¦é€‰æ‹©ä¸­æ–‡æ¨¡å‹
    if (content.length > 300 || lowerContent.includes('å¤æ‚') || lowerContent.includes('è¯¦ç»†')) {
      return 'hunyuan-t1-latest'; // å¤æ‚ä¸­æ–‡ä»»åŠ¡
    }
    return 'hunyuan-turbos-latest'; // ä¸€èˆ¬ä¸­æ–‡ä»»åŠ¡
  }

  // é»˜è®¤ä½¿ç”¨å¿«é€Ÿé€šç”¨æ¨¡å‹
  return 'gemini-flash-lite';
}

// å°† OpenAI æ ¼å¼è½¬æ¢ä¸º LangChain æ ¼å¼
export function convertOpenAIToLangChain(request: OpenAICompletionRequest): {
  messages: VercelChatMessage[];
  model?: string;
  temperature?: number;
  maxTokens?: number;
  stream?: boolean;
} {
  const messages: VercelChatMessage[] = request.messages.map(msg => {
    if (msg.role === 'tool') {
      // å·¥å…·æ¶ˆæ¯è½¬æ¢ä¸ºç³»ç»Ÿæ¶ˆæ¯
      return {
        id: Math.random().toString(36),
        role: 'system' as const,
        content: `Tool result: ${msg.content}`
      };
    }

    return {
      id: Math.random().toString(36),
      role: msg.role as 'user' | 'assistant' | 'system',
      content: Array.isArray(msg.content) 
        ? msg.content.map(c => c.type === 'text' ? c.text : c).join(' ')
        : msg.content
    };
  });

  // æ˜ å°„æ¨¡å‹åç§°
  const mappedModel = MODEL_MAPPING[request.model] || request.model;

  return {
    messages,
    model: mappedModel === 'auto' ? undefined : mappedModel,
    temperature: request.temperature,
    maxTokens: request.max_tokens,
    stream: request.stream ?? true
  };
}

// ç”Ÿæˆ OpenAI æ ¼å¼çš„å“åº”
export function createOpenAIResponse(
  content: string,
  model: string = 'langchain-auto',
  isComplete: boolean = false,
  isStream: boolean = true
): OpenAICompletionResponse {
  const timestamp = Math.floor(Date.now() / 1000);
  const id = `chatcmpl-${Math.random().toString(36).substring(2, 15)}`;

  if (isStream) {
    return {
      id,
      object: 'chat.completion.chunk',
      created: timestamp,
      model,
      choices: [{
        index: 0,
        delta: isComplete ? {} : { content },
        finish_reason: isComplete ? 'stop' : null
      }]
    };
  } else {
    return {
      id,
      object: 'chat.completion',
      created: timestamp,
      model,
      choices: [{
        index: 0,
        message: {
          role: 'assistant',
          content
        },
        finish_reason: 'stop'
      }],
      usage: {
        prompt_tokens: 0, // è¿™é‡Œå¯ä»¥å®é™…è®¡ç®—
        completion_tokens: 0,
        total_tokens: 0
      }
    };
  }
}

// åˆ›å»ºæµå¼å“åº”çš„æ•°æ®æ ¼å¼
export function formatStreamChunk(response: OpenAICompletionResponse): string {
  return `data: ${JSON.stringify(response)}\n\n`;
}

// åˆ›å»ºæµå¼å“åº”ç»“æŸæ ‡è®°
export function createStreamEnd(): string {
  return 'data: [DONE]\n\n';
}

// æ£€æµ‹è¯·æ±‚æ„å›¾å¹¶è¿”å›ç›¸åº”çš„ç«¯ç‚¹è·¯å¾„
export function detectIntentFromRequest(request: OpenAICompletionRequest): string {
  const lastMessage = request.messages[request.messages.length - 1];
  const content = Array.isArray(lastMessage.content) 
    ? lastMessage.content.map(c => c.type === 'text' ? c.text : '').join(' ')
    : lastMessage.content;

  // æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡
  const hasImage = request.messages.some(msg => 
    Array.isArray(msg.content) && 
    msg.content.some(c => c.type === 'image_url')
  );

  if (hasImage) {
    return '/api/chat'; // è§†è§‰å¤„ç†
  }

  const lowerContent = content.toLowerCase();

  // æ£€æµ‹æœç´¢è¯·æ±‚
  if (lowerContent.includes('search') || 
      lowerContent.includes('latest') || 
      lowerContent.includes('current') ||
      lowerContent.includes('news')) {
    return '/api/chat/agents';
  }

  // æ£€æµ‹ç»“æ„åŒ–è¾“å‡ºè¯·æ±‚
  if (lowerContent.includes('analyze') || 
      lowerContent.includes('structure') || 
      lowerContent.includes('format') ||
      lowerContent.includes('json')) {
    return '/api/chat/structured_output';
  }

  // æ£€æµ‹æ–‡æ¡£æ£€ç´¢è¯·æ±‚
  if (lowerContent.includes('document') || 
      lowerContent.includes('rag') || 
      lowerContent.includes('retrieval') ||
      lowerContent.includes('langchain')) {
    return '/api/chat/retrieval';
  }

  // æ£€æµ‹Agentè¯·æ±‚
  if (lowerContent.includes('tool') || 
      lowerContent.includes('function') || 
      lowerContent.includes('calculate') ||
      request.tools && request.tools.length > 0) {
    return '/api/chat/agents';
  }

  // é»˜è®¤ä½¿ç”¨åŸºç¡€èŠå¤©
  return '/api/chat';
}

// è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
export function getSupportedModels() {
  return [
    {
      id: 'auto',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'langchain'
    },
    {
      id: 'gpt-4',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'openai'
    },
    {
      id: 'gpt-4-turbo',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'openai'
    },
    {
      id: 'gpt-3.5-turbo',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'openai'
    },
    {
      id: 'claude-3-5-sonnet',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'anthropic'
    },
    {
      id: 'gemini-pro',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'google'
    },
    {
      id: 'deepseek-chat',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'deepseek'
    },
    {
      id: 'hunyuan-turbos-latest',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'tencent'
    },
    {
      id: 'hunyuan-t1-latest',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'tencent'
    },
    {
      id: 'langchain-chat',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'langchain'
    },
    {
      id: 'langchain-vision',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'langchain'
    },
    {
      id: 'langchain-search',
      object: 'model',
      created: Math.floor(Date.now() / 1000),
      owned_by: 'langchain'
    }
  ];
}

// æ ¼å¼åŒ–æ¨¡å‹ä¿¡æ¯æ³¨å…¥
export function formatModelInjection(
  content: string,
  modelName: string,
  options: {
    useMarkdown?: boolean;
    addSeparator?: boolean;
    compact?: boolean;
    detectStructured?: boolean;
  } = {}
): string {
  const {
    useMarkdown = true,
    addSeparator = true,
    compact = false,
    detectStructured = true
  } = options;

  // å¦‚æœå†…å®¹ä¸ºç©ºï¼Œç›´æ¥è¿”å›
  if (!content || !content.trim()) {
    return content;
  }

  // æ£€æµ‹å†…å®¹ç±»å‹
  const isStructuredContent = detectStructured && (
    content.includes('```') ||
    content.includes('```json') ||
    content.includes('```javascript') ||
    content.includes('```python') ||
    content.includes('```sql') ||
    content.includes('**') ||
    content.includes('##') ||
    content.includes('###') ||
    content.includes('- ') ||
    content.includes('1. ') ||
    content.includes('| ') // è¡¨æ ¼
  );

  // æ£€æµ‹æ˜¯å¦ä¸ºé”™è¯¯ä¿¡æ¯æˆ–æŠ€æœ¯å†…å®¹
  const isTechnicalContent =
    content.includes('error') ||
    content.includes('Error') ||
    content.includes('undefined') ||
    content.includes('Cannot read properties') ||
    content.includes('API') ||
    content.includes('é…ç½®') ||
    content.includes('å‚æ•°');

  let modelInfo: string;
  let separator: string;

  if (compact) {
    // ç´§å‡‘æ ¼å¼
    modelInfo = `ğŸ¤– ${modelName}`;
    separator = ' â€¢ ';
  } else if (useMarkdown) {
    // æ ‡å‡†Markdownæ ¼å¼
    modelInfo = `ğŸ¤– **Model:** ${modelName}`;
    separator = addSeparator ? '\n\n---\n\n' : '\n\n';
  } else {
    // çº¯æ–‡æœ¬æ ¼å¼
    modelInfo = `ğŸ¤– Model: ${modelName}`;
    separator = addSeparator ? '\n---\n' : '\n';
  }

  // å¯¹äºç»“æ„åŒ–å†…å®¹ï¼Œä½¿ç”¨ä»£ç å—æ ¼å¼
  if (isStructuredContent && useMarkdown && !compact) {
    return `\`\`\`\n${modelInfo}\n${addSeparator ? '---' : ''}\n\`\`\`\n\n${content}`;
  }

  // å¯¹äºæŠ€æœ¯å†…å®¹ï¼Œä½¿ç”¨å¼•ç”¨æ ¼å¼
  if (isTechnicalContent && useMarkdown && !compact) {
    return `> ${modelInfo}\n\n${content}`;
  }

  // æ ‡å‡†æ ¼å¼
  return `${modelInfo}${separator}${content}`;
}

// æ£€æµ‹å†…å®¹æ˜¯å¦éœ€è¦ç‰¹æ®Šæ ¼å¼åŒ–
export function detectContentType(content: string): {
  isCode: boolean;
  isStructured: boolean;
  isTechnical: boolean;
  isLongForm: boolean;
} {
  const isCode = content.includes('```') ||
                 /^[\s]*[{}\[\]()=;]/.test(content) ||
                 content.includes('function') ||
                 content.includes('const ') ||
                 content.includes('let ') ||
                 content.includes('var ');

  const isStructured = content.includes('**') ||
                       content.includes('##') ||
                       content.includes('###') ||
                       content.includes('- ') ||
                       content.includes('1. ') ||
                       content.includes('| ') ||
                       content.includes('```');

  const isTechnical = content.includes('error') ||
                      content.includes('Error') ||
                      content.includes('API') ||
                      content.includes('é…ç½®') ||
                      content.includes('å‚æ•°') ||
                      content.includes('undefined') ||
                      content.includes('Cannot read');

  const isLongForm = content.length > 500;

  return {
    isCode,
    isStructured,
    isTechnical,
    isLongForm
  };
}

// æ™ºèƒ½æ ¼å¼åŒ–å‡½æ•° - æ ¹æ®å†…å®¹ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ ¼å¼
export function smartFormatModelInjection(
  content: string,
  modelName: string
): string {
  const contentType = detectContentType(content);
  
  // æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©æ ¼å¼åŒ–é€‰é¡¹
  let options = {
    useMarkdown: true,
    addSeparator: true,
    compact: false,
    detectStructured: true
  };

  // å¯¹äºä»£ç å†…å®¹ï¼Œä½¿ç”¨ç´§å‡‘æ ¼å¼
  if (contentType.isCode) {
    options.compact = true;
    options.addSeparator = false;
  }
  
  // å¯¹äºæŠ€æœ¯å†…å®¹ï¼Œä½¿ç”¨å¼•ç”¨æ ¼å¼
  if (contentType.isTechnical) {
    options.addSeparator = false;
  }
  
  // å¯¹äºé•¿å†…å®¹ï¼Œä½¿ç”¨æ ‡å‡†æ ¼å¼
  if (contentType.isLongForm) {
    options.addSeparator = true;
  }

  return formatModelInjection(content, modelName, options);
}

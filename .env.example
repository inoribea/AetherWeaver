# ===== 统一智能路由系统环境变量配置 =====
# 基于 LangChain 的统一智能路由架构和语义分析系统
# 文档: https://github.com/langchain-ai/langchain-nextjs-template
# 详细说明: ./UNIFIED_ROUTER_README.md

# ===== 基础配置 =====
# 应用基础信息
VERCEL_APP_URL="https://localhost:3000"
APP_TITLE="LangChain 统一智能路由系统"

# ===== 模型 API 密钥配置 =====
# 注意: 至少配置一个模型 API 密钥，系统会自动检测可用模型

# --- 1. Google Gemini (推荐: 成本低、速度快) ---
GOOGLE_API_KEY="your-google-api-key"
# 可选: 自定义 Base URL
# GOOGLE_BASE_URL="https://generativelanguage.googleapis.com"

# --- 2. OpenAI (功能全面) ---
OPENAI_API_KEY="your-openai-api-key"
OPENAI_BASE_URL=""  # 可选: 自定义 Base URL

# --- 3. DeepSeek (中文友好、推理能力强) ---
DEEPSEEK_API_KEY="your-deepseek-api-key"

# --- 4. 阿里云通义千问 (中文优化) ---
DASHSCOPE_API_KEY="your-dashscope-api-key"

# --- 5. 自定义 OpenAI 兼容提供商 ---
# 示例: Neko API (支持多种模型)
NEKO_API_KEY="your-neko-api-key"
NEKO_BASE_URL="your-neko-base-url"

# --- Claude 专用配置 (顶尖复杂任务处理) ---
CLAUDE_API_KEY="your-claude-api-key"
CLAUDE_BASE_URL="https://api.anthropic.com"

# 示例: 其他 OpenAI 兼容提供商
O3_API_KEY="your-o3-api-key"
O3_BASE_URL="your-o3-base-url"

# OpenRouter (多模型聚合)
OPENROUTER_API_KEY="your-openrouter-api-key"
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"

# --- 6. 其他模型提供商 ---
# Tencent Hunyuan
TENCENT_HUNYUAN_SECRET_ID="your-tencent-secret-id"
TENCENT_HUNYUAN_SECRET_KEY="your-tencent-secret-key"

# Cloudflare Workers AI
CLOUDFLARE_API_TOKEN="your-cloudflare-api-token"
CLOUDFLARE_ACCOUNT_ID="your-cloudflare-account-id"

# ===== 统一智能路由系统配置 =====
# 统一路由器功能开关
ENABLE_UNIFIED_ROUTING="true"
ENABLE_INTELLIGENT_ROUTING="true"
ENABLE_MODEL_SWITCHING="true"
ENABLE_PERFORMANCE_MONITORING="true"

# 路由决策配置
ROUTING_CONFIDENCE_THRESHOLD="0.7"
ROUTING_FALLBACK_MODEL="gpt-4o-all"
ROUTING_CACHE_TTL="300"  # 路由缓存时间(秒)

# 统一路由器配置
UNIFIED_ROUTER_SEMANTIC_ANALYSIS="true"
UNIFIED_ROUTER_CAPABILITY_MATCHING="true"
UNIFIED_ROUTER_EXPLICIT_MODEL_SUPPORT="true"
UNIFIED_ROUTER_FALLBACK_CHAIN="true"

# 复杂度阈值模型优先级配置 (用逗号分隔的模型列表)
COMPLEXITY_HIGH_MODELS="claude-sonnet-4-all,gpt-4o-all,deepseek-reasoner,hunyuan-t1-latest"
COMPLEXITY_MEDIUM_MODELS="gpt-4o-all,gemini-flash,qwen-turbo,hunyuan-turbos-latest,claude-sonnet-4-all"
COMPLEXITY_LOW_MODELS="gemini-flash,qwen-turbo,hunyuan-turbos-latest,gpt-4o-all"

# 模型选择策略权重
MODEL_SELECTION_CAPABILITY_WEIGHT="0.4"
MODEL_SELECTION_COST_WEIGHT="0.3"
MODEL_SELECTION_PERFORMANCE_WEIGHT="0.3"

# ===== 高级功能配置 =====

# --- 网络搜索功能 ---
TAVILY_API_KEY="your-tavily-api-key"
SERPAPI_API_KEY="your-serpapi-api-key"
BING_SEARCH_API_KEY="your-bing-search-api-key"

# --- RAG 检索功能 ---
# Supabase (推荐)
SUPABASE_URL="your-supabase-url"
SUPABASE_SERVICE_ROLE_KEY="your-supabase-service-role-key"
SUPABASE_TABLE_NAME="documents"

# Pinecone (云向量数据库)
PINECONE_API_KEY="your-pinecone-api-key"
PINECONE_ENVIRONMENT="your-pinecone-environment"
PINECONE_INDEX_NAME="langchain-chat-index"

# Chroma (本地向量数据库)
CHROMA_COLLECTION_NAME="chat-documents"
CHROMA_SERVER_URL="http://localhost:8000"
CHROMA_PERSIST_DIRECTORY="./chroma-data"

# --- 向量嵌入配置 ---
# Cloudflare Embeddings (推荐: 成本低、速度快)
CLOUDFLARE_EMBEDDING_MODEL="@cf/baai/bge-base-en-v1.5"
CLOUDFLARE_EMBEDDING_DIMENSIONS="768"

# 可选: OpenAI Embeddings (仅在需要时启用)
# OPENAI_EMBEDDINGS_MODEL="text-embedding-3-large"
# OPENAI_EMBEDDINGS_DIMENSIONS="1024"

# ===== OpenAI 兼容 API 配置 =====
# 启用 OpenAI 兼容 API 端点
ENABLE_OPENAI_COMPATIBLE_API="true"

# API 密钥验证配置
ENABLE_API_AUTH="true"

# 方式1: 多个 API 密钥 (逗号分隔)
LANGCHAIN_API_KEYS="sk-langchain-key1,sk-langchain-key2,sk-langchain-key3"

# 方式2: 编号的单独密钥 (支持1-10)
LANGCHAIN_API_KEY_1="sk-langchain-user-key-1"
LANGCHAIN_API_KEY_2="sk-langchain-user-key-2"
LANGCHAIN_API_KEY_3="sk-langchain-user-key-3"

# 方式3: 单个默认密钥
LANGCHAIN_API_KEY="sk-langchain-default-key"

# 管理员密钥 (拥有所有权限)
LANGCHAIN_ADMIN_KEY="sk-langchain-admin-super-secret"

# ===== 智能代理配置 =====
# 代理执行配置
AGENT_MAX_ITERATIONS="10"
AGENT_MAX_EXECUTION_TIME="30"  # 秒
AGENT_VERBOSE="false"

# 工具配置
ENABLE_AGENT_TOOLS="true"
PYTHON_REPL_ENABLED="false"
SANDBOX_ENVIRONMENT="docker"  # docker, local, none

# 数学计算工具
WOLFRAM_ALPHA_APP_ID="your-wolfram-alpha-app-id"

# ===== 结构化输出配置 =====
STRUCTURED_OUTPUT_ENABLED="true"
STRUCTURED_OUTPUT_VALIDATION="true"
STRUCTURED_OUTPUT_MAX_RETRIES="3"

# ===== 检索配置 =====
RETRIEVAL_TOP_K="5"
RETRIEVAL_SCORE_THRESHOLD="0.7"
RETRIEVAL_SEARCH_TYPE="similarity"  # similarity, mmr, similarity_score_threshold
RETRIEVAL_FETCH_K="20"

# 文档处理配置
DOCUMENT_CHUNK_SIZE="1000"
DOCUMENT_CHUNK_OVERLAP="200"
DOCUMENT_MAX_FILE_SIZE="10485760"  # 10MB

# ===== 内存和持久化配置 =====
ENABLE_MEMORY="true"
MEMORY_PROVIDER="buffer"  # buffer, summary, token_buffer, conversation_kg
MEMORY_MAX_TOKEN_LIMIT="4000"
MEMORY_RETURN_MESSAGES="true"

# LangGraph 状态持久化
DATABASE_URL="postgresql://user:password@host:port/database?schema=public"
REDIS_URL="redis://localhost:6379/0"

# ===== 监控和日志配置 =====
# LangSmith 追踪 (强烈推荐)
LANGCHAIN_TRACING_V2="true"
LANGCHAIN_API_KEY="your-langsmith-api-key"
LANGCHAIN_PROJECT="langchain-intelligent-routing"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"

# 应用日志配置
LOG_LEVEL="info"  # debug, info, warn, error
LOG_FORMAT="json"  # json, text
ENABLE_REQUEST_LOGGING="true"

# 性能监控
ENABLE_PERFORMANCE_METRICS="true"
METRICS_ENDPOINT="/api/metrics"

# ===== 性能和限制配置 =====
# 并发和超时
MAX_CONCURRENT_REQUESTS="10"
REQUEST_TIMEOUT="30000"  # 毫秒
RATE_LIMIT_REQUESTS_PER_MINUTE="60"

# 缓存配置
ENABLE_RESPONSE_CACHE="false"
CACHE_TTL="3600"  # 秒
CACHE_PROVIDER="memory"  # memory, redis, none
REDIS_CACHE_URL="redis://localhost:6379/1"

# ===== 安全配置 =====
# CORS 配置
ENABLE_CORS="true"
ALLOWED_ORIGINS="http://localhost:3000,https://your-domain.com"

# API 认证
API_KEY_HEADER="X-API-Key"
API_SECRET_KEY="your-secret-key"

# ===== 功能开关 =====
# 核心功能
ENABLE_VISION_PROCESSING="true"
ENABLE_WEB_SEARCH="true"
ENABLE_DOCUMENT_RETRIEVAL="true"
ENABLE_STRUCTURED_OUTPUT="true"
ENABLE_AGENT_TOOLS="true"
ENABLE_COMPLEX_REASONING="true"

# 语言优化
ENABLE_CHINESE_OPTIMIZATION="true"
ENABLE_MULTILINGUAL_SUPPORT="true"

# 高级功能
ENABLE_MODEL_FALLBACK="true"
ENABLE_AUTOMATIC_RETRIES="true"
ENABLE_CONTEXT_AWARENESS="true"

# ===== 开发和测试配置 =====
NODE_ENV="development"  # development, production, test
DEBUG_MODE="false"
MOCK_API_RESPONSES="false"
TEST_API_KEY="test-key-for-development"

# 开发工具
ENABLE_BUNDLE_ANALYZER="false"
ENABLE_PERFORMANCE_PROFILING="false"

# ===== 部署配置 =====
# 生产环境配置
LANGCHAIN_CALLBACKS_BACKGROUND="false"  # Vercel Edge Functions 要求
VERCEL_ENV="production"  # Vercel 自动设置

# 健康检查
ENABLE_HEALTH_CHECK="true"
HEALTH_CHECK_ENDPOINT="/api/health"

# ===== 统一智能路由系统使用说明 =====
#
# 🚀 快速开始:
# 1. 至少配置一个模型 API 密钥
# 2. 运行: npm run dev
# 3. 访问: http://localhost:3000
# 4. 使用 "model": "auto" 享受智能路由
#
# 🔧 添加新模型:
# 方式1: npm run add-model (交互式)
# 方式2: 编辑 models-config.json
# 方式3: 访问 /admin/models 管理界面
# 方式4: 使用统一路由器 API 动态注册
#
# 🧪 测试系统:
# node scripts/test-unified-router.js  # 统一路由器测试
# npm run test-router                  # 传统路由器测试
#
# 📚 详细文档:
# 查看 README.md 和 UNIFIED_ROUTER_README.md
#
# ===== 推荐的最小配置 =====
#
# # 基础配置 (选择一个)
# GOOGLE_API_KEY="your-google-api-key"     # 推荐: 成本低、速度快
# # 或
# NEKO_API_KEY="your-neko-api-key"         # 高级模型: GPT-4o, Claude
# # 或
# DEEPSEEK_API_KEY="your-deepseek-api-key" # 推理专家: 中文友好
#
# # 可选功能
# TAVILY_API_KEY="your-tavily-api-key"     # 网络搜索
# SUPABASE_URL="your-supabase-url"         # RAG 检索
# LANGCHAIN_API_KEY="your-langsmith-key"   # 监控追踪
#
# ===== 统一路由器最佳配置 =====
#
# # 多模型配置 (获得最佳智能路由性能)
# NEKO_API_KEY="your-neko-api-key"         # GPT-4o-all, Claude-sonnet-4-all
# DEEPSEEK_API_KEY="your-deepseek-api-key" # deepseek-reasoner (推理专家)
# DASHSCOPE_API_KEY="your-dashscope-key"   # qwen-turbo, qvq-plus (中文+视觉)
# GOOGLE_API_KEY="your-google-api-key"     # gemini-flash (搜索+速度)
# TENCENT_HUNYUAN_SECRET_ID="your-secret-id"     # 腾讯混元
# TENCENT_HUNYUAN_SECRET_KEY="your-secret-key"   # (中文创作)
#
# # 完整功能配置
# TAVILY_API_KEY="your-tavily-api-key"     # 网络搜索
# SUPABASE_URL="your-supabase-url"         # RAG 检索
# LANGCHAIN_API_KEY="your-langsmith-key"   # 监控追踪
#
# ===== 智能路由示例 =====
#
# # 视觉任务: "请分析这张图片" → qvq-plus
# # 推理任务: "分析量子计算原理" → deepseek-reasoner
# # 中文创作: "写一首诗" → hunyuan-t1-latest
# # 代码生成: "写Python代码" → claude-sonnet-4-all
# # 搜索任务: "最新新闻" → gemini-flash
# # 明确指定: "让Claude分析" → claude-sonnet-4-all
#
# ===== 故障排除 =====
#
# 🔍 常见问题:
# 1. 模型不可用: 检查 API 密钥是否正确
# 2. 路由不准确: 运行 node scripts/test-unified-router.js 检查
# 3. 性能问题: 启用缓存和监控
# 4. 配置错误: 检查 models-config.json 格式
#
# 🛠️ 调试命令:
# node scripts/test-unified-router.js  # 测试统一路由器
# npm run models:list                  # 查看可用模型
# npm run test-router                  # 测试传统路由器
# npm run models:reload                # 重新加载配置
#
# 📊 监控:
# 访问 /admin/models 查看模型状态
# 查看控制台日志了解路由决策
# 使用 OpenAI 兼容 API: /api/v1/chat/completions
#
# ===== API 使用示例 =====
#
# # 使用统一智能路由
# curl -X POST http://localhost:3000/api/v1/chat/completions \
#   -H "Content-Type: application/json" \
#   -d '{"model": "auto", "messages": [{"role": "user", "content": "你好"}]}'
#
# # 重载配置
# curl -X POST http://localhost:3000/api/admin/models/reload
#
# # 查看模型列表
# curl -X GET http://localhost:3000/api/v1/models

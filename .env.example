# =============================
# 环境变量示例 (.env.example)
# 复制为 .env 或 .env.local 使用；按需填写。
# 重要：仅选择一个“聊天模型提供商”分组（A 或 B），不要混用。
# =============================

# ============ 通用开关 ============
# 自定义 API 鉴权（仅 /api/v1/* 需要）。true 则调用方需携带 Authorization: Bearer <访问key>
ENABLE_API_AUTH=true
# 允许访问的用户级访问 key（逗号分隔），示例：LANGCHAIN_API_KEYS=user1,user2
LANGCHAIN_API_KEYS=
# 管理员访问 key（部分管理端接口需要）
LANGCHAIN_ADMIN_KEY=

# ============ A. 官方 OpenAI ============
# 仅在使用官方 OpenAI 时填写本组，并确保不要设置 OPENAI_BASE_URL 为第三方地址
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1

# 可选：链内默认模型，避免回退到不存在的占位名（按需调整）
BASIC_MODEL_NAME=gpt-4o-mini
RAG_MODEL_NAME=gpt-4o
VISION_MODEL_NAME=gpt-4o-mini

# 可选：v1 兼容入口的“默认模型名”
DEFAULT_MODEL_NAME=gpt-4o-mini

# ============ B. OpenAI 兼容提供商（通用）===========
# 规则：任何 PREFIX_API_KEY + PREFIX_BASE_URL 均可（如 NEKO、O3、OPENROUTER 等）
# 指定默认兼容提供商前缀（可选），不区分大小写：示例 OPENAI / NEKO / O3 / OPENROUTER...
OPENAI_COMPAT_PROVIDER=

# 示例：PREFIX 提供商
PREFIX_API_KEY=
PREFIX_BASE_URL=https://prefix.com/v1

# （推荐）仅对特定路由使用第三方真实模型名（models-config.json 中存在的真实名）
# 常用：Qwen/Qwen3-235B-A22B-search 或 deepseek-ai/DeepSeek-V3-search
BASIC_MODELS=Qwen/Qwen3-235B-A22B-search
STRUCTURED_OUTPUT_MODELS=Qwen/Qwen3-235B-A22B-search

# 可选：将链内默认模型也换成上述真实模型名，避免默认占位名
# BASIC_MODEL_NAME=Qwen/Qwen3-235B-A22B-search
# RAG_MODEL_NAME=Qwen/Qwen3-235B-A22B-search
# VISION_MODEL_NAME=Qwen/Qwen3-235B-A22B-search

# ============ 其他提供商密钥（按需）===========
DEEPSEEK_API_KEY=
GOOGLE_API_KEY=

# 阿里通义：app/api/chat/route.ts 使用 DASHSCOPE_API_KEY；agents 示例使用 ALIBABA_API_KEY
DASHSCOPE_API_KEY=
ALIBABA_API_KEY=

# 腾讯混元
TENCENT_HUNYUAN_SECRET_ID=
TENCENT_HUNYUAN_SECRET_KEY=

# ============ Embeddings ============
# 方案1：OpenAI Embeddings（默认沿用 OPENAI_API_KEY / OPENAI_BASE_URL）
OPENAI_EMBEDDINGS_MODEL=text-embedding-3-small
OPENAI_EMBEDDINGS_DIMENSIONS=1536

# 方案2：Cloudflare Workers AI Embeddings（两者必填）
# CLOUDFLARE_API_TOKEN=
# CLOUDFLARE_ACCOUNT_ID=
# CLOUDFLARE_EMBEDDING_MODEL=@cf/baai/bge-base-en-v1.5
# EMBEDDING_PROVIDER=Cloudflare

# ============ 工具与可观测（可选）===========
SERPAPI_API_KEY=
TAVILY_API_KEY=

# Langfuse（本项目使用 LANGFUSE_API_URL / LANGFUSE_API_KEY）
LANGFUSE_API_URL=
LANGFUSE_API_KEY=

# ============ 检索与向量库（可选）===========
QDRANT_URL=

# Pinecone
# PINECONE_API_KEY=
# PINECONE_ENVIRONMENT=
# PINECONE_INDEX=

# Postgres / Neon
# DATABASE_URL=

# Upstash Vector（注意 REST 变量名）
# UPSTASH_VECTOR_REST_URL=
# UPSTASH_VECTOR_REST_TOKEN=

# ============ 路由模型池覆盖（真实模型名，逗号分隔，可选）===========
# ENHANCED_TASKS_MODELS=
# VISION_TASKS_MODELS=
# REASONING_TASKS_MODELS=
# CHINESE_TASKS_MODELS=
# SEARCH_TASKS_MODELS=
# CODE_TASKS_MODELS=
# CREATIVE_TASKS_MODELS=
# STRUCTURED_OUTPUT_MODELS=

# ============ 其它（可选）===========
NEXT_PUBLIC_APP_URL=
VERCEL_REGION=iad1
VERCEL_FUNCTION_TIMEOUT=30

# .env.local or Vercel Environment Variables

# For OpenRouter HTTP-Referer header
VERCEL_APP_URL="https://localhost:3000" 
# For OpenRouter X-Title header
APP_TITLE="LangChain Vercel API"

# For Base Openai
OPENAI_BASE_URL=""
OPENAI_API_KEY=""

# --- 1. Aliyun Bailian / DashScope (Tongyi) ---
# Reference: https://js.langchain.com/docs/integrations/chat/alibaba_tongyi
# The API Key for ChatTongyi is DASHSCOPE_API_KEY.
DASHSCOPE_API_KEY="sk-your_dashscope_api_key"
# If using OpenAI compatible mode, you might need to set baseURL
# ALIBABA_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1"

# --- 2. DeepSeek ---
# Reference: https://js.langchain.com/docs/integrations/chat/deepseek
DEEPSEEK_API_KEY="sk-your_deepseek_api_key"

# --- 3. Cloudflare Workers AI ---
# Reference: https://js.langchain.com/docs/integrations/chat/cloudflare_workersai/
CLOUDFLARE_API_TOKEN="your_cloudflare_api_token"
CLOUDFLARE_ACCOUNT_ID="your_cloudflare_account_id"

# --- 4. Tencent Hunyuan ---
# Reference: https://js.langchain.com/docs/integrations/chat/tencent_hunyuan/
TENCENT_HUNYUAN_SECRET_ID="your_tencent_hunyuan_secret_id"
TENCENT_HUNYUAN_SECRET_KEY="your_tencent_hunyuan_secret_key"
# Optional: Specify region or endpoint if needed
# TENCENT_HUNYUAN_REGION="ap-guangzhou"
# TENCENT_HUNYUAN_ENDPOINT="hunyuan.cloud.tencent.com"

# --- 5. Google Gemini ---
# Reference: https://js.langchain.com/docs/integrations/chat/google_generative_ai/
GOOGLE_API_KEY="your_google_api_key"
# Optional: Set a specific base URL if needed
# GOOGLE_BASE_URL="https://generativelanguage.googleapis.com"

# --- Other environment variables (keep or add as needed) ---
# Custom OpenAI Compatible Provider A
NEKO_API_KEY="..."
NEKO_BASE_URL="..."

# Custom OpenAI Compatible Provider B
O3_API_KEY="..."
O3_BASE_URL="..."

# OpenRouter
OPENROUTER_API_KEY="..."
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"

# LangSmith (Highly Recommended for Tracing)
LANGCHAIN_TRACING_V2="true"
LANGCHAIN_API_KEY="placeholder"
LANGCHAIN_PROJECT="placeholder"

# LangGraph (State Persistence)
# LangGraph requires external storage for state persistence in serverless environments.
# Example: PostgreSQL database connection string for checkpointing.
# DATABASE_URL="postgresql://user:password@host:port/database?schema=public"
# Example: Redis connection string for checkpointing.
# REDIS_URL="redis://localhost:6379/0"

# RAG / Tools (If used)
PINECONE_API_KEY="..."
PINECONE_INDEX_NAME="..."
TAVILY_API_KEY="..."

# ===== ENHANCED FEATURES ENVIRONMENT VARIABLES =====

# --- Vector Store & Embeddings ---
# OpenAI Embeddings Configuration
OPENAI_EMBEDDINGS_MODEL="text-embedding-3-large"
OPENAI_EMBEDDINGS_DIMENSIONS="1024"

# --- Vector Database Options (Choose one) ---
# Option 1: Pinecone (Cloud Vector Database)
PINECONE_ENVIRONMENT="your-pinecone-environment"
PINECONE_INDEX_NAME="langchain-chat-index"

# Option 2: Chroma (Local/Self-hosted Vector Database)
CHROMA_COLLECTION_NAME="chat-documents"
CHROMA_SERVER_URL="http://localhost:8000"
CHROMA_PERSIST_DIRECTORY="./chroma-data"

# Option 3: Supabase (PostgreSQL with pgvector)
SUPABASE_URL="your-supabase-url"
SUPABASE_SERVICE_ROLE_KEY="your-supabase-service-role-key"
SUPABASE_TABLE_NAME="documents"

# --- Document Processing Configuration ---
DOCUMENT_CHUNK_SIZE="1000"
DOCUMENT_CHUNK_OVERLAP="200"
DOCUMENT_MAX_FILE_SIZE="10485760"  # 10MB in bytes

# --- Agent Configuration ---
AGENT_MAX_ITERATIONS="10"
AGENT_MAX_EXECUTION_TIME="30"  # seconds
AGENT_VERBOSE="false"

# --- Structured Output Configuration ---
STRUCTURED_OUTPUT_ENABLED="true"
STRUCTURED_OUTPUT_VALIDATION="true"
STRUCTURED_OUTPUT_MAX_RETRIES="3"

# --- Retrieval Settings ---
RETRIEVAL_TOP_K="5"
RETRIEVAL_SCORE_THRESHOLD="0.7"
RETRIEVAL_SEARCH_TYPE="similarity"  # similarity, mmr, similarity_score_threshold
RETRIEVAL_FETCH_K="20"  # for MMR search

# --- Additional Tools Configuration ---
# Search Tools
SERPAPI_API_KEY="your-serpapi-key"
BING_SEARCH_API_KEY="your-bing-search-key"
BING_SEARCH_URL="https://api.bing.microsoft.com/v7.0/search"

# Math and Computation
WOLFRAM_ALPHA_APP_ID="your-wolfram-alpha-app-id"

# Code Execution (if needed)
PYTHON_REPL_ENABLED="false"
SANDBOX_ENVIRONMENT="docker"  # docker, local, none

# --- Memory and Persistence Configuration ---
ENABLE_MEMORY="true"
MEMORY_PROVIDER="buffer"  # buffer, summary, token_buffer, conversation_kg
MEMORY_MAX_TOKEN_LIMIT="4000"
MEMORY_RETURN_MESSAGES="true"

# --- Logging and Monitoring ---
# LangSmith Enhanced Configuration
LANGSMITH_API_KEY="your-langsmith-api-key"
LANGSMITH_PROJECT_NAME="langchain-chat-enhanced"
LANGSMITH_TRACING="true"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"

# Application Logging
LOG_LEVEL="info"  # debug, info, warn, error
LOG_FORMAT="json"  # json, text
ENABLE_REQUEST_LOGGING="true"

# --- Performance and Rate Limiting ---
MAX_CONCURRENT_REQUESTS="10"
REQUEST_TIMEOUT="30000"  # milliseconds
RATE_LIMIT_REQUESTS_PER_MINUTE="60"

# --- Security Configuration ---
ENABLE_CORS="true"
ALLOWED_ORIGINS="http://localhost:3000,https://your-domain.com"
API_KEY_HEADER="X-API-Key"  # Optional: for API authentication
API_SECRET_KEY="your-secret-key"  # Optional: for API authentication

# --- Feature Flags ---
ENABLE_VISION_PROCESSING="true"
ENABLE_WEB_SEARCH="true"
ENABLE_DOCUMENT_RETRIEVAL="true"
ENABLE_STRUCTURED_OUTPUT="true"
ENABLE_AGENT_TOOLS="true"
ENABLE_COMPLEX_REASONING="true"

# --- Cache Configuration ---
ENABLE_RESPONSE_CACHE="false"
CACHE_TTL="3600"  # seconds
CACHE_PROVIDER="memory"  # memory, redis, none
REDIS_CACHE_URL="redis://localhost:6379/1"

# --- Development and Testing ---
NODE_ENV="development"  # development, production, test
DEBUG_MODE="false"
MOCK_API_RESPONSES="false"
TEST_API_KEY="test-key-for-development"

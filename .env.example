##################################################
#              项目环境变量配置示例              #
##################################################

# ========== 1. Vercel 部署相关环境变量 =================

VERCEL_FUNCTION_TIMEOUT=30
VERCEL_ENV=production
VERCEL_APP_URL="https://localhost:3000"
VERCEL_PROJECT_ID=
VERCEL_ORG_ID=
NEXT_PUBLIC_APP_URL="https://localhost:3000"

# ========== 2. API Key及访问控制 =====================

OPENAI_API_KEY=
OPENAI_BASE_URL=
DEEPSEEK_API_KEY=
GOOGLE_API_KEY=
GOOGLE_BASE_URL="https://generativelanguage.googleapis.com"
CLAUDE_API_KEY="your-claude-api-key"
CLAUDE_BASE_URL="https://api.anthropic.com"
TENCENT_HUNYUAN_SECRET_ID=
TENCENT_HUNYUAN_SECRET_KEY=
DASHSCOPE_API_KEY=
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"


CLOUDFLARE_API_TOKEN=
CLOUDFLARE_ACCOUNT_ID=
CLOUDFLARE_EMBEDDING_MODEL=@cf/baai/bge-base-en-v1.5
SERPAPI_API_KEY=
TAVILY_API_KEY=
ENABLE_API_AUTH=true

LANGCHAIN_API_KEYS="sk-langchain-1,sk-langchain-2,sk-langchain-3"
LANGCHAIN_ADMIN_KEY="sk-langchain-admin-1"
#LANGCHAIN_API_KEY="your-langsmith-api-key"
#LANGCHAIN_PROJECT="langchain-intelligent-routing"
#LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
#LANGCHAIN_TRACING_V2="true"

LANGFUSE_API_URL="your-langfuse-api-url"
LANGFUSE_API_KEY="your-langfuse-api-key"
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=

# ========== 3. 向量数据库及存储配置 ===============

DATABASE_URL=
UPSTASH_VECTOR_REST_URL=
UPSTASH_VECTOR_REST_TOKEN=
QDRANT_URL=http://localhost:6333
PINECONE_API_KEY=
PINECONE_ENVIRONMENT=

# ========== 4. 模型及嵌入配置 ==================

OPENAI_EMBEDDINGS_MODEL=text-embedding-3-small
OPENAI_EMBEDDINGS_DIMENSIONS=1536
EMBEDDING_PROVIDER=
BASIC_MODEL_NAME=gpt-5-mini
RAG_MODEL_NAME=gpt-5
OPENAI_MODEL_NAME=gpt-5-mini

# ========== 5. 统一路由与代理配置 =================
ROUTING_CACHE_TTL="300"
ROUTING_MODEL_NAME="gpt-5-nano" # 用于智能路由增强的LLM模型名称
ROUTING_PROMPT="请基于以下用户输入和规则分析结果，判断最合适的路由模式（{routes}, basic），并给出置信度（0-1）：\n用户输入：{text}\n规则分析结果：{ruleResult}\n\n请仅返回JSON格式：\n{\n  \"route\": \"路由名称\",\n  \"confidence\": 置信度,\n  \"analysis_method\": \"llm_enhanced\"\n}"
ROUTING_TEMPERATURE="0"
ROUTING_TOP_P="1"

# ========== 6. 文档处理与分段配置 =================

DOCUMENT_CHUNK_SIZE=1000
DOCUMENT_CHUNK_OVERLAP=200

# ========== 7. 各路由路径模型池配置 =====================
# 通过环境变量覆盖 models-config.json 中为每个路由定义的 preferred_models
# 请在此处使用 models-config.json 中定义的真实模型名，而不是键名
# 模型名称之间用逗号分隔，第一个模型为首选模型

ENHANCED_TASKS_MODELS="models/gemini-2.5-flash-preview-05-20,gpt,claude-sonnet-4-all,deepseek-reasoner"
VISION_TASKS_MODELS="gpt-5-all,qvq-plus,claude-sonnet-4-all"
REASONING_TASKS_MODELS="deepseek-reasoner,claude-sonnet-4-all,hunyuan-t1-latest"
CHINESE_TASKS_MODELS="qwen-turbo-latest,deepseek-reasoner,hunyuan-turbos-latest,hunyuan-t1-latest"
SEARCH_TASKS_MODELS="gpt,Qwen/Qwen3-235B-A22B-search,deepseek-ai/DeepSeek-V3-search"
CODE_TASKS_MODELS="gpt,qwen-turbo-latest,deepseek-reasoner"
CREATIVE_TASKS_MODELS="claude-sonnet-4-all,hunyuan-t1-latest,gpt"
STRUCTURED_OUTPUT_TASKS_MODELS="models/gemini-2.5-flash-preview-05-20,gpt,claude-sonnet-4-all,hunyuan-turbos-latest"

# ========== 10. 其他调试及运行时配置 ================

AGENT_SYSTEM_PROMPT=


# Smart Router Configuration
# ANALYSIS_MODE: "rule_based" or "llm_enhanced". Defaults to "rule_based".
ANALYSIS_MODE=rule_based

# LANGFLOW_ROUTER_MEMORY_SUPPORT: JSON string to control memory support, e.g., {"enabled": true}.
# Alternatively, can be a simple boolean "true" or "false".
LANGFLOW_ROUTER_MEMORY_SUPPORT=true
```
from __future__ import annotations

import time
import uuid
from typing import Any, Dict

from langflow.custom.custom_component.component import Component
from langflow.io import HandleInput, MessageInput, Output, DropdownInput, BoolInput
from langflow.schema.message import Message

class OptimizedSmartRoutingFunction(Component):
    display_name = "Optimized Smart Routing Function"
    description = "LCEL-compatible LLM-powered intelligent routing with enhanced decision logic and memory support"
    icon = "square-function"
    name = "OptimizedSmartRoutingFunction"

    inputs = [
        MessageInput(
            name="input_message",
            display_name="Input Message",
            info="Enhanced message from RoutingChatOutput or MessageMemory with routing analysis",
            required=True,
        ),
        HandleInput(
            name="llm",
            display_name="Language Model",
            info="Language Model for intelligent routing analysis",
            input_types=["LanguageModel"],
            required=False,
        ),
        DropdownInput(
            name="analysis_mode",
            display_name="Analysis Mode",
            options=["llm_enhanced", "hybrid", "fast_rule"],
            value="hybrid",
            info="Routing analysis strategy",
            advanced=False,
        ),
        BoolInput(
            name="enable_confidence_boost",
            display_name="Enable Confidence Boost",
            info="Use pre-analysis to boost confidence",
            value=True,
            advanced=True,
        ),
        DropdownInput(
            name="default_route",
            display_name="Default Route",
            options=["basic", "enhanced", "rag", "agent"],
            value="basic",
            info="Fallback route when analysis fails",
            advanced=True,
        ),
        BoolInput(
            name="pass_route_as_text",
            display_name="Pass Route as Text",
            info="If enabled, pass route decision as text; if disabled, pass original user input",
            value=False,
            advanced=False,
        ),
        BoolInput(
            name="include_route_in_text",
            display_name="Include Route in Text",
            info="If enabled, prepend route decision to original text",
            value=False,
            advanced=False,
        ),
    ]

    outputs = [
        Output(
            display_name="LCEL Routing Output",
            name="lcel_routing_output",
            method="get_lcel_routing_output"
        ),
    ]

    def safe_extract_routing_data(self, message_input: Any) -> Dict[str, Any]:
        """å®‰å…¨æå–è·¯ç”±æ•°æ®ï¼ŒåŒ…æ‹¬è®°å¿†ä¿¡æ¯"""
        routing_data = {
            "text": "",
            "conversation_history": "",
            "pre_analysis": {},
            "routing_hint": None,
            "confidence": 0.5,
            "metadata": {}
        }
        
        try:
            if message_input is None:
                return routing_data
            
            # å¤„ç†Messageå¯¹è±¡
            if hasattr(message_input, 'text'):
                full_text = str(message_input.text) if message_input.text else ""
                
                # æ£€æŸ¥æ˜¯å¦æ¥è‡ªMessageMemoryï¼ˆåŒ…å«å¯¹è¯åŽ†å²ï¼‰
                if '\n' in full_text and ('Human:' in full_text or 'Assistant:' in full_text or 'User:' in full_text):
                    # æ¥è‡ªMessageMemoryçš„æ ¼å¼åŒ–å¯¹è¯åŽ†å²
                    lines = full_text.split('\n')
                    
                    # æå–å½“å‰ç”¨æˆ·è¾“å…¥ï¼ˆé€šå¸¸æ˜¯æœ€åŽä¸€è¡Œæˆ–æœ€åŽçš„Human/Useræ¶ˆæ¯ï¼‰
                    current_input = ""
                    conversation_lines = []
                    
                    for line in reversed(lines):
                        line = line.strip()
                        if not line:
                            continue
                        if line.startswith(('Human:', 'User:')) and not current_input:
                            current_input = line.split(':', 1)[1].strip()
                        else:
                            conversation_lines.insert(0, line)
                    
                    routing_data["text"] = current_input or full_text
                    routing_data["conversation_history"] = '\n'.join(conversation_lines) if conversation_lines else ""
                else:
                    # æ™®é€šç”¨æˆ·è¾“å…¥
                    routing_data["text"] = full_text
                
                # æå–metadataä¸­çš„é¢„åˆ†æžç»“æžœ
                if hasattr(message_input, 'metadata') and message_input.metadata:
                    metadata = message_input.metadata
                    routing_data["metadata"] = metadata
                    
                    # æå–é¢„åˆ†æžç»“æžœ
                    if 'routing_analysis' in metadata:
                        routing_data["pre_analysis"] = metadata['routing_analysis']
                        routing_data["routing_hint"] = metadata['routing_analysis'].get('routing_decision')
                        routing_data["confidence"] = metadata['routing_analysis'].get('confidence', 0.5)
                    
                    # ç›´æŽ¥æå–è·¯ç”±æç¤º
                    routing_data["routing_hint"] = routing_data["routing_hint"] or metadata.get('routing_hint') or metadata.get('route')
            else:
                routing_data["text"] = str(message_input) if message_input else ""
            
            return routing_data
            
        except Exception as e:
            self.status = f"âŒ Data extraction error: {str(e)[:30]}..."
            return routing_data

    def enhanced_rule_analysis(self, text: str, conversation_history: str = "") -> Dict[str, Any]:
        """å¢žå¼ºçš„è§„åˆ™åˆ†æžï¼Œè€ƒè™‘å¯¹è¯åŽ†å²"""
        text_lower = text.lower()
        history_lower = conversation_history.lower()
        
        # åŸºäºŽåŽ†å²ä¸Šä¸‹æ–‡çš„åˆ†æž
        if conversation_history:
            # æ£€æŸ¥åŽ†å²ä¸­çš„åˆ›ä½œç±»ä»»åŠ¡å»¶ç»­
            if any(word in history_lower for word in ["å†™", "åˆ›ä½œ", "è¯—", "sonnet", "æ•…äº‹", "å°è¯´"]):
                if any(word in text_lower for word in ["ç»§ç»­", "æŽ¥ç€", "ä¸‹ä¸€", "æ›´å¤š", "å†æ¥"]):
                    return {"route": "enhanced", "confidence": 0.85, "method": "rule_history_enhanced"}
            
            # æ£€æŸ¥åŽ†å²ä¸­çš„æœç´¢ç±»ä»»åŠ¡å»¶ç»­
            if any(word in history_lower for word in ["æŸ¥æ‰¾", "æœç´¢", "æ£€ç´¢", "èµ„æ–™"]):
                if any(word in text_lower for word in ["ç»§ç»­", "æ›´å¤š", "è¯¦ç»†", "è¿˜æœ‰"]):
                    return {"route": "rag", "confidence": 0.8, "method": "rule_history_rag"}
        
        # Enhanced è·¯ç”±çš„å…³é”®è¯
        enhanced_keywords = [
            "å†™", "åˆ›ä½œ", "ç”Ÿæˆ", "ç¼–å†™", "ä½œæ–‡", "è¯—", "sonnet", "å°è¯´", "æ•…äº‹", "å‰§æœ¬",
            "åˆ†æž", "è§£é‡Š", "è¯¦ç»†", "æ·±å…¥", "ä¸“ä¸š", "å¤æ‚", "å…¨é¢", "ç³»ç»Ÿ",
            "ç ”ç©¶", "ç†è®º", "å­¦æœ¯", "è®ºæ–‡", "æŠ¥å‘Š", "æ–¹æ¡ˆ", "ç­–ç•¥",
            "æŠ€æœ¯", "ç®—æ³•", "ä»£ç ", "ç¼–ç¨‹", "å¼€å‘", "è®¾è®¡", "æž¶æž„",
            "å»ºè®®", "æŒ‡å¯¼", "æ–¹æ¡ˆ", "è§„åˆ’", "ä¼˜åŒ–", "æ”¹è¿›"
        ]
        
        # Agent è·¯ç”±çš„å…³é”®è¯
        agent_keywords = [
            "è®¡ç®—", "æ‰§è¡Œ", "è°ƒç”¨", "è¿è¡Œ", "æŸ¥è¯¢", "æœç´¢", "èŽ·å–", "ä¸‹è½½", 
            "ä¸Šä¼ ", "å‘é€", "å¤„ç†", "è½¬æ¢", "ç¿»è¯‘", "api", "tool", "å·¥å…·"
        ]
        
        # RAG è·¯ç”±çš„å…³é”®è¯  
        rag_keywords = [
            "æŸ¥æ‰¾", "æœç´¢", "æ‰¾", "æ£€ç´¢", "èµ„æ–™", "æ–‡æ¡£", "è®°å½•", "åŽ†å²",
            "æ•°æ®åº“", "çŸ¥è¯†åº“", "æ–‡ä»¶", "æ¡£æ¡ˆ"
        ]
        
        # ç»Ÿè®¡åŒ¹é…æ•°é‡
        enhanced_matches = sum(1 for keyword in enhanced_keywords if keyword in text_lower)
        agent_matches = sum(1 for keyword in agent_keywords if keyword in text_lower)  
        rag_matches = sum(1 for keyword in rag_keywords if keyword in text_lower)
        
        # æ–‡æœ¬é•¿åº¦å’Œå¤æ‚åº¦åˆ†æž
        text_length = len(text)
        sentence_count = len([s for s in text.split('ã€‚') if s.strip()])
        
        # å†³ç­–é€»è¾‘
        if agent_matches >= 2 or any(word in text_lower for word in ["api", "å·¥å…·", "æ‰§è¡Œ", "è®¡ç®—"]):
            return {"route": "agent", "confidence": 0.85, "method": "rule_agent"}
            
        elif rag_matches >= 2 or any(word in text_lower for word in ["æŸ¥æ‰¾", "æœç´¢", "èµ„æ–™"]):
            return {"route": "rag", "confidence": 0.8, "method": "rule_rag"}
            
        elif (enhanced_matches >= 2 or 
              text_length > 50 or 
              sentence_count > 1 or
              any(word in text_lower for word in ["å†™", "åˆ›ä½œ", "åˆ†æž", "è¯¦ç»†", "ä¸“ä¸š", "sonnet", "è¯—"])):
            return {"route": "enhanced", "confidence": 0.8, "method": "rule_enhanced"}
        
        else:
            return {"route": "basic", "confidence": 0.6, "method": "rule_basic"}

    def llm_enhanced_routing_analysis(self, routing_data: Dict[str, Any]) -> Dict[str, Any]:
        """LLMå¢žå¼ºçš„è·¯ç”±åˆ†æžï¼ŒåŒ…å«è®°å¿†ä¸Šä¸‹æ–‡"""
        text = routing_data["text"]
        conversation_history = routing_data.get("conversation_history", "")
        pre_analysis = routing_data.get("pre_analysis", {})
        pre_hint = routing_data.get("routing_hint")
        
        if not text:
            return self._create_fallback_result("basic", 0.5, "empty_input")
        
        # å¦‚æžœæ²¡æœ‰LLMï¼Œä½¿ç”¨å¢žå¼ºè§„åˆ™åˆ†æž
        if not hasattr(self, 'llm') or not self.llm:
            rule_result = self.enhanced_rule_analysis(text, conversation_history)
            return rule_result
        
        try:
            # åŒ…å«è®°å¿†çš„LLMåˆ†æžæç¤ºè¯
            if conversation_history:
                analysis_prompt = f"""è¯·åŸºäºŽå¯¹è¯åŽ†å²åˆ†æžç”¨æˆ·å½“å‰æ¶ˆæ¯çš„è·¯ç”±éœ€æ±‚ã€‚

å¯¹è¯åŽ†å²:
{conversation_history}

å½“å‰ç”¨æˆ·æ¶ˆæ¯: "{text}"

è·¯ç”±é€‰é¡¹è¯¦ç»†è¯´æ˜Ž:
- basic: ç®€å•é—®ç­”ã€æ—¥å¸¸å¯¹è¯ã€åŸºç¡€ä¿¡æ¯æŸ¥è¯¢
  ç¤ºä¾‹: "ä½ å¥½"ã€"è°¢è°¢"ã€"ä»Šå¤©å¤©æ°”æ€Žä¹ˆæ ·"
  
- enhanced: éœ€è¦æ·±åº¦æ€è€ƒã€åˆ›ä½œã€ä¸“ä¸šåˆ†æžçš„å¤æ‚ä»»åŠ¡  
  ç¤ºä¾‹: "å†™ä¸€é¦–åå››è¡Œè¯—"ã€"åˆ†æžå¸‚åœºè¶‹åŠ¿"ã€"è§£é‡Šé‡å­åŠ›å­¦"ã€"è®¾è®¡æ–¹æ¡ˆ"
  
- rag: éœ€è¦æŸ¥æ‰¾å…·ä½“èµ„æ–™ã€æ–‡æ¡£ã€åŽ†å²è®°å½•çš„ä»»åŠ¡
  ç¤ºä¾‹: "æŸ¥æ‰¾ç›¸å…³èµ„æ–™"ã€"æœç´¢æ–‡æ¡£"ã€"æ‰¾åˆ°åŽ†å²è®°å½•"
  
- agent: éœ€è¦è°ƒç”¨å·¥å…·ã€æ‰§è¡Œè®¡ç®—ã€APIè°ƒç”¨çš„ä»»åŠ¡  
  ç¤ºä¾‹: "è®¡ç®—æ•°æ®"ã€"æ‰§è¡Œä»£ç "ã€"è°ƒç”¨API"ã€"å¤„ç†æ–‡ä»¶"

åˆ†æžè¦ç‚¹:
1. è€ƒè™‘å¯¹è¯åŽ†å²çš„ä¸Šä¸‹æ–‡è¿žç»­æ€§
2. åˆ¤æ–­å½“å‰æ¶ˆæ¯æ˜¯å¦æ˜¯å¯¹ä¹‹å‰å¯¹è¯çš„å»¶ç»­
3. è¯„ä¼°æ‰€éœ€çš„å¤„ç†å¤æ‚åº¦å’Œä¸“ä¸šç¨‹åº¦
4. ç‰¹åˆ«æ³¨æ„åˆ›ä½œã€åˆ†æžç±»ä»»åŠ¡çš„å»¶ç»­æ€§

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›žç­”ï¼Œåªè¿”å›žè·¯ç”±åç§°å’Œç½®ä¿¡åº¦:
route:è·¯ç”±åç§°,confidence:0.XX"""
            else:
                analysis_prompt = f"""è¯·ä»”ç»†åˆ†æžä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯ï¼Œç¡®å®šæœ€é€‚åˆçš„å¤„ç†è·¯ç”±ã€‚

ç”¨æˆ·æ¶ˆæ¯: "{text}"

è·¯ç”±é€‰é¡¹è¯¦ç»†è¯´æ˜Ž:
- basic: ç®€å•é—®ç­”ã€æ—¥å¸¸å¯¹è¯ã€åŸºç¡€ä¿¡æ¯æŸ¥è¯¢
  ç¤ºä¾‹: "ä½ å¥½"ã€"è°¢è°¢"ã€"ä»Šå¤©å¤©æ°”æ€Žä¹ˆæ ·"
  
- enhanced: éœ€è¦æ·±åº¦æ€è€ƒã€åˆ›ä½œã€ä¸“ä¸šåˆ†æžçš„å¤æ‚ä»»åŠ¡  
  ç¤ºä¾‹: "å†™ä¸€é¦–åå››è¡Œè¯—"ã€"åˆ†æžå¸‚åœºè¶‹åŠ¿"ã€"è§£é‡Šé‡å­åŠ›å­¦"ã€"è®¾è®¡æ–¹æ¡ˆ"
  
- rag: éœ€è¦æŸ¥æ‰¾å…·ä½“èµ„æ–™ã€æ–‡æ¡£ã€åŽ†å²è®°å½•çš„ä»»åŠ¡
  ç¤ºä¾‹: "æŸ¥æ‰¾ç›¸å…³èµ„æ–™"ã€"æœç´¢æ–‡æ¡£"ã€"æ‰¾åˆ°åŽ†å²è®°å½•"
  
- agent: éœ€è¦è°ƒç”¨å·¥å…·ã€æ‰§è¡Œè®¡ç®—ã€APIè°ƒç”¨çš„ä»»åŠ¡  
  ç¤ºä¾‹: "è®¡ç®—æ•°æ®"ã€"æ‰§è¡Œä»£ç "ã€"è°ƒç”¨API"ã€"å¤„ç†æ–‡ä»¶"

åˆ†æžè¦ç‚¹:
1. ä»»åŠ¡çš„å¤æ‚ç¨‹åº¦å’Œæ·±åº¦è¦æ±‚
2. æ˜¯å¦éœ€è¦åˆ›é€ æ€§æ€ç»´  
3. æ˜¯å¦éœ€è¦å¤–éƒ¨èµ„æºæˆ–å·¥å…·
4. é¢„æœŸå›žç­”çš„è¯¦ç»†ç¨‹åº¦

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›žç­”ï¼Œåªè¿”å›žè·¯ç”±åç§°å’Œç½®ä¿¡åº¦:
route:è·¯ç”±åç§°,confidence:0.XX"""
            
            # è°ƒç”¨LLM
            response = self.llm.invoke(analysis_prompt)
            llm_result = self._parse_llm_response(response.content)
            
            # ç»“åˆé¢„åˆ†æžå’ŒLLMåˆ†æžç»“æžœ
            final_result = self._combine_analysis_results(pre_analysis, llm_result, routing_data)
            return final_result
                
        except Exception as e:
            self.status = f"âš ï¸ LLM analysis failed: {str(e)[:30]}..."
            # LLMå¤±è´¥æ—¶ä½¿ç”¨å¢žå¼ºè§„åˆ™åˆ†æž
            rule_result = self.enhanced_rule_analysis(text, conversation_history)
            return rule_result

    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """è§£æžLLMå“åº”"""
        try:
            route = "basic"
            confidence = 0.7
            
            response_lower = response.lower().strip()
            
            # æå–è·¯ç”±
            if "route:" in response_lower:
                try:
                    route_part = response_lower.split("route:")[1].split(",")[0].strip()
                    if route_part in ["basic", "enhanced", "rag", "agent"]:
                        route = route_part
                except:
                    pass
            else:
                # ç›´æŽ¥åŒ¹é…è·¯ç”±åç§°ï¼ˆenhancedä¼˜å…ˆï¼‰
                for r in ["enhanced", "agent", "rag", "basic"]:
                    if r in response_lower:
                        route = r
                        break
            
            # æå–ç½®ä¿¡åº¦
            if "confidence:" in response_lower:
                try:
                    conf_part = response_lower.split("confidence:")[1].split(",")[0].strip()
                    confidence = float(conf_part)
                    confidence = max(0.0, min(1.0, confidence))
                except:
                    confidence = 0.7
            
            return {
                "route": route,
                "confidence": confidence,
                "method": "llm_analysis"
            }
            
        except Exception:
            return {"route": "basic", "confidence": 0.5, "method": "llm_parse_error"}

    def _combine_analysis_results(self, pre_analysis: Dict, llm_result: Dict, routing_data: Dict) -> Dict[str, Any]:
        """ç»“åˆé¢„åˆ†æžå’ŒLLMåˆ†æžç»“æžœ"""
        
        pre_route = routing_data.get("routing_hint", "basic")
        pre_confidence = routing_data.get("confidence", 0.5)
        
        llm_route = llm_result["route"]
        llm_confidence = llm_result["confidence"]
        
        # æ™ºèƒ½ç»“åˆç­–ç•¥
        if self.analysis_mode == "llm_enhanced":
            # ä»¥LLMä¸ºä¸»
            final_route = llm_route
            final_confidence = llm_confidence
            
            if pre_route == llm_route and self.enable_confidence_boost:
                final_confidence = min(1.0, final_confidence + 0.1)
                
        elif self.analysis_mode == "hybrid":
            # å¹³è¡¡ç­–ç•¥ - ä¼˜å…ˆè€ƒè™‘éžbasicè·¯ç”±
            if llm_route != "basic" and llm_confidence >= 0.6:
                final_route = llm_route  
                final_confidence = llm_confidence
            elif pre_route != "basic" and pre_confidence >= 0.6:
                final_route = pre_route
                final_confidence = pre_confidence
            elif llm_confidence > pre_confidence:
                final_route = llm_route
                final_confidence = llm_confidence
            else:
                final_route = pre_route
                final_confidence = pre_confidence
                
        else:  # fast_rule
            rule_result = self.enhanced_rule_analysis(routing_data["text"], routing_data.get("conversation_history", ""))
            final_route = rule_result["route"]
            final_confidence = rule_result["confidence"]
        
        return {
            "route": final_route,
            "confidence": final_confidence,
            "method": f"{self.analysis_mode}_combined",
            "pre_analysis": pre_analysis,
            "llm_analysis": llm_result,
            "original_text": routing_data["text"],
            "conversation_history": routing_data.get("conversation_history", ""),
            "analysis_timestamp": time.time()
        }

    def _create_fallback_result(self, route: str, confidence: float, method: str) -> Dict[str, Any]:
        """åˆ›å»ºåŽå¤‡ç»“æžœ"""
        return {
            "route": route,
            "confidence": confidence,
            "method": method,
            "fallback": True,
            "timestamp": time.time()
        }

    def get_lcel_routing_output(self) -> Message:
        """è¿”å›žLCELå…¼å®¹çš„è·¯ç”±è¾“å‡ºï¼ŒåŒ…å«è®°å¿†ä¿¡æ¯"""
        
        # æå–è·¯ç”±æ•°æ®ï¼ˆåŒ…æ‹¬è®°å¿†ï¼‰
        routing_data = self.safe_extract_routing_data(self.input_message)
        original_text = routing_data.get("text", "")
        conversation_history = routing_data.get("conversation_history", "")
        
        # æ‰§è¡Œæ™ºèƒ½è·¯ç”±åˆ†æž
        analysis_result = self.llm_enhanced_routing_analysis(routing_data)
        
        # åˆ›å»ºLCELå…¼å®¹çš„è¾“å‡ºMessage
        route = analysis_result["route"]
        confidence = analysis_result["confidence"]
        
        # æ ¹æ®å¼€å…³å†³å®šæ¶ˆæ¯å†…å®¹
        if self.pass_route_as_text:
            message_text = route
        elif self.include_route_in_text and original_text:
            message_text = f"[{route.upper()}] {original_text}"
        else:
            message_text = original_text
        
        # æž„å»ºå®Œæ•´çš„metadataï¼ŒåŒ…å«è®°å¿†ä¿¡æ¯
        lcel_metadata = {
            # æ ¸å¿ƒè·¯ç”±ä¿¡æ¯
            "route": route,
            "routing_decision": route,
            "routing_hint": route,
            "confidence": confidence,
            
            # åŽŸå§‹è¾“å…¥ä¿å­˜
            "original_user_input": original_text,
            "original_text": original_text,
            
            # è®°å¿†ä¿¡æ¯
            "conversation_history": conversation_history,
            "has_memory": bool(conversation_history),
            "memory_length": len(conversation_history) if conversation_history else 0,
            
            # åˆ†æžè¯¦æƒ…
            "analysis_result": analysis_result,
            "analysis_method": analysis_result.get("method", "unknown"),
            "analysis_mode": self.analysis_mode,
            
            # æ–‡æœ¬ä¼ é€’æ–¹å¼
            "pass_route_as_text": self.pass_route_as_text,
            "include_route_in_text": self.include_route_in_text,
            
            # LCELå…¼å®¹æ€§æ ‡è®°
            "lcel_compatible": True,
            "openai_format": True,
            "component_source": "OptimizedSmartRoutingFunction",
            
            # æ—¶é—´æˆ³å’Œè¿½è¸ª
            "timestamp": time.time(),
            "routing_id": str(uuid.uuid4()),
            
            # æ¡ä»¶æ•°æ®
            "conditions": {
                "is_basic": route == "basic",
                "is_enhanced": route == "enhanced",
                "is_rag": route == "rag",
                "is_agent": route == "agent",
                "confidence_sufficient": confidence >= 0.6,
                "requires_fallback": confidence < 0.5
            },
            
            # æŠ€æœ¯ç»†èŠ‚
            "technical_info": {
                "llm_available": hasattr(self, 'llm') and self.llm is not None,
                "enable_confidence_boost": self.enable_confidence_boost,
                "default_route": self.default_route,
                "original_text_length": len(original_text),
                "has_pre_analysis": bool(routing_data.get("pre_analysis")),
                "has_conversation_history": bool(conversation_history),
                "message_construction": {
                    "pass_route_as_text": self.pass_route_as_text,
                    "include_route_in_text": self.include_route_in_text,
                    "final_text_type": "route" if self.pass_route_as_text else ("prefixed" if self.include_route_in_text else "original")
                }
            }
        }
        
        # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
        method_short = analysis_result.get("method", "unknown")[:15]
        memory_indicator = "ðŸ“" if conversation_history else "ðŸ†•"
        self.status = f"âœ… Route: {route.upper()} ({confidence:.2f}) | {method_short} {memory_indicator}"
        
        return Message(
            text=message_text,
            metadata=lcel_metadata
        )

```

